{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb5793f-80b2-4c6b-b15b-51abf33c83e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6091b6be",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3 in /opt/conda/envs/myenv/lib/python3.8/site-packages (1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3) (1.19.2)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3) (1.6.0)\n",
      "Requirement already satisfied: gym>=0.17 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3) (0.18.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3) (1.4.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3) (1.2.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3) (3.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines3) (8.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/myenv/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->stable-baselines3) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from pandas->stable-baselines3) (2021.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e928c2a5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines\n",
      "  Downloading stable_baselines-2.10.2-py3-none-any.whl (240 kB)\n",
      "\u001b[K     |████████████████████████████████| 240 kB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines) (1.2.5)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 61.8 MB 4.0 MB/s eta 0:00:012   |███▉                            | 7.3 MB 4.7 MB/s eta 0:00:12     |█████████████                   | 25.3 MB 16.0 MB/s eta 0:00:03     |██████████████▍                 | 27.8 MB 16.0 MB/s eta 0:00:03     |███████████████                 | 28.8 MB 16.0 MB/s eta 0:00:03     |███████████████▌                | 29.9 MB 16.0 MB/s eta 0:00:02     |█████████████████               | 32.9 MB 16.0 MB/s eta 0:00:02     |█████████████████▊              | 34.3 MB 16.0 MB/s eta 0:00:02     |██████████████████▍             | 35.6 MB 16.0 MB/s eta 0:00:02     |███████████████████             | 36.5 MB 879 kB/s eta 0:00:29     |███████████████████▌            | 37.7 MB 879 kB/s eta 0:00:28     |██████████████████████▏         | 42.8 MB 879 kB/s eta 0:00:22     |████████████████████████████    | 54.1 MB 879 kB/s eta 0:00:09     |█████████████████████████████▎  | 56.5 MB 4.0 MB/s eta 0:00:02     |███████████████████████████████▉| 61.5 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines) (1.19.2)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gym[atari,classic_control]>=0.11 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines) (0.18.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines) (3.4.2)\n",
      "Requirement already satisfied: cloudpickle>=0.5.5 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines) (1.6.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines) (1.6.2)\n",
      "Collecting atari-py~=0.2.0\n",
      "  Downloading atari_py-0.2.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/envs/myenv/lib/python3.8/site-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.11->stable-baselines) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines) (8.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from pandas->stable-baselines) (2021.1)\n",
      "Installing collected packages: opencv-python, atari-py, joblib, stable-baselines\n",
      "Successfully installed atari-py-0.2.9 joblib-1.2.0 opencv-python-4.7.0.68 stable-baselines-2.10.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: stable-baselines3[extra] in /opt/conda/envs/myenv/lib/python3.8/site-packages (1.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.6.0)\n",
      "Requirement already satisfied: gym>=0.17 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.18.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3[extra]) (3.4.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.2.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.19.2)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3[extra]) (8.2.0)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.2.9)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.5.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/myenv/lib/python3.8/site-packages (from stable-baselines3[extra]) (4.7.0.68)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[K     |████████████████████████████████| 280 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/envs/myenv/lib/python3.8/site-packages (from atari-py~=0.2.0->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.13.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.36.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (49.6.0.post20210108)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.17.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.32.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.38.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/myenv/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2021.1)\n",
      "Installing collected packages: psutil\n",
      "Successfully installed psutil-5.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install stable-baselines --upgrade\n",
    "! pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a9f67b-265e-401e-85c7-55b3827c9e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_env import make_reversi_vec_env, SelfPlayEnv\n",
    "import torch as th\n",
    "from players import RandomPlayer\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b07411d1-263f-445f-9dc8-92ef55cd4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_shape = 8\n",
    "n_envs = 10\n",
    "env = make_reversi_vec_env(\n",
    "    SelfPlayEnv, n_envs=n_envs,\n",
    "    env_kwargs={\n",
    "        'board_shape': board_shape,\n",
    "        'LocalPlayer': RandomPlayer\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f7b6a-ab0b-495f-9b9b-03220308f75b",
   "metadata": {},
   "source": [
    "# Modificación de librería para que haga argmax solo sobre las válidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65966e76-d302-40f5-be6a-1b00565194cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    ActorCriticPolicy,\n",
    "    env,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac109405-906a-4c2e-92bd-0ab6d8146190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  1  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  1  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  1  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "env_reset = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "424e3f5e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40, 27, 31, 50,  2, 31, 26, 46, 29, 60]), None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(env_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8ae4f-2113-4031-8b6a-3b8210285937",
   "metadata": {},
   "source": [
    "# Custom ActorCriticPolicy \n",
    "\n",
    "https://github.com/DLR-RM/stable-baselines3/blob/master/stable_baselines3/common/policies.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4552377-3076-44dd-a6d4-d504b5915e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boardgame2 import ReversiEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b9569a-4fed-4508-8cbd-73b7aac5058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_not_vect = ReversiEnv(board_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a85eaa1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "state = env_reset[0][0]\n",
    "player = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7dd0bfa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., -1., -1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1., -1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_reset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58553f62-ab53-41b9-9815-df9706caffc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_not_vect.get_valid((env_reset[0][0], player))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "682d4c7b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_not_vect.get_valid((env_reset[2][0], player))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4898c124-9b43-4088-a366-03adc8b31ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions_mask(state):\n",
    "    player = 1\n",
    "    valid_actions = env_not_vect.get_valid((state, player))\n",
    "    return valid_actions.reshape(-1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d92fe71-689f-4a7f-8f0b-4ee7453a4db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_actions_mask(env.reset()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f3d239d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#import policies_custom\n",
    "import torch as th\n",
    "from torch import nn\n",
    "from stable_baselines3.common.preprocessing import get_action_dim, maybe_transpose, preprocess_obs\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor, FlattenExtractor, MlpExtractor, NatureCNN, create_mlp\n",
    "from stable_baselines3.common.type_aliases import Schedule\n",
    "from stable_baselines3.common.utils import get_device, is_vectorized_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4422dc4a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args, # Todos los argumentos posicionales de ActorCriticPolicy\n",
    "        actions_mask_func=None, # El nuevo argumento\n",
    "        **kwargs # Todos los argumentos opcionales de ActorCriticPolicy\n",
    "    ):\n",
    "        super(CustomActorCriticPolicy, self).__init__(\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        if actions_mask_func:\n",
    "            self.get_actions_mask = actions_mask_func\n",
    "    \n",
    "    \n",
    "    \n",
    "    def sample_masked_actions(self, obs, distribution, deterministic=False, return_distribution=False):\n",
    "        # Dada las obs y distribuciones luego de evaluar la red neuronal, samplear solo las acciones válidas\n",
    "        # Las obs se usan para que con self.get_actions_mask se obtengan las acciones válidas\n",
    "        # las distribuciones son el resultado de evaluar la red neuronal y van a dar acciones no validas\n",
    "        # Generar una nueva distribución (del lado de los logits preferentemente) donde las acciones no válidas\n",
    "        # tengan probabildad nula de ser muestreadas\n",
    "        # Luego se modifican abajo los métodos\n",
    "        # _predict, forward y evaluate_actions\n",
    "        # Si tiene el flag de return_distribution en true devuelve la distribución nueva\n",
    "        # Caso contrario devuelve las acciones\n",
    "        # Para tener en cuenta, obs tiene dimensión [batch_size, channels, H, W]\n",
    "        # Recomendamos poner un print(obs.shape)\n",
    "        # y correr:\n",
    "        # obs = env.reset()\n",
    "        # actions, _ = model.predict(obs)\n",
    "        # Para sacarse las dudas\n",
    "        masked_logits = []\n",
    "        for i, obs in enumerate(obs):\n",
    "            board = obs[0]\n",
    "            acc = self.get_actions_mask(board)\n",
    "            masked_logits.append(th.from_numpy(acc))\n",
    "        if distribution:\n",
    "            return th.distributions.Categorical(logits=masked_logits)\n",
    "        if deterministic:\n",
    "            return th.argmax(masked_logits, axis=1)\n",
    "        return th.distributions.Categorical(logits=masked_logits).sample()\n",
    "    \n",
    "    def _predict(self, observation, deterministic=False):\n",
    "        \"\"\"\n",
    "        Get the action according to the policy for a given observation.\n",
    "        :param observation:\n",
    "        :param deterministic: Whether to use stochastic or deterministic actions\n",
    "        :return: Taken action according to the policy\n",
    "        \"\"\"\n",
    "        latent_pi, _, latent_sde = self._get_latent(observation)\n",
    "        distribution = self._get_action_dist_from_latent(latent_pi, latent_sde)\n",
    "        \n",
    "        if self.get_actions_mask:\n",
    "            actions = self.sample_masked_actions(observation, distribution.distribution, deterministic=deterministic)\n",
    "        else:\n",
    "            actions = distribution.get_actions(deterministic=deterministic)\n",
    "        \n",
    "        return actions\n",
    "    \n",
    "    def forward(self, obs, deterministic = False):\n",
    "        \"\"\"\n",
    "        Forward pass in all the networks (actor and critic)\n",
    "        :param obs: Observation\n",
    "        :param deterministic: Whether to sample or use deterministic actions\n",
    "        :return: action, value and log probability of the action\n",
    "        \"\"\"\n",
    "        latent_pi, latent_vf, latent_sde = self._get_latent(obs)\n",
    "        # Evaluate the values for the given observations\n",
    "        values = self.value_net(latent_vf)\n",
    "        distribution = self._get_action_dist_from_latent(latent_pi, latent_sde=latent_sde)\n",
    "        \n",
    "        \n",
    "        if self.get_actions_mask:\n",
    "            actions = self.sample_masked_actions(obs, distribution.distribution, deterministic=deterministic)\n",
    "        else:\n",
    "            actions = distribution.get_actions(deterministic=deterministic)\n",
    "\n",
    "        log_prob = distribution.log_prob(actions)\n",
    "        return actions, values, log_prob\n",
    "    \n",
    "    def evaluate_actions(self, obs, actions):\n",
    "        \"\"\"\n",
    "        Evaluate actions according to the current policy,\n",
    "        given the observations.\n",
    "        :param obs:\n",
    "        :param actions:\n",
    "        :return: estimated value, log likelihood of taking those actions\n",
    "            and entropy of the action distribution.\n",
    "        \"\"\"\n",
    "        latent_pi, latent_vf, latent_sde = self._get_latent(obs)\n",
    "        distribution = self._get_action_dist_from_latent(latent_pi, latent_sde)\n",
    "        distrib = self.sample_masked_actions(obs, distribution.distribution, return_distribution=True)\n",
    "\n",
    "        log_prob = distrib.log_prob(actions)\n",
    "        values = self.value_net(latent_vf)\n",
    "        return values, log_prob, distrib.entropy()\n",
    "\n",
    "\n",
    "    def _get_latent(self, obs):\n",
    "        \"\"\"\n",
    "        Get the latent code (i.e., activations of the last layer of each network)\n",
    "        for the different networks.\n",
    "\n",
    "        :param obs: Observation\n",
    "        :return: Latent codes\n",
    "            for the actor, the value function and for gSDE function\n",
    "        \"\"\"\n",
    "        # Preprocess the observation if needed\n",
    "        features = self.extract_features(obs)\n",
    "        latent_pi, latent_vf = self.mlp_extractor(features)\n",
    "\n",
    "        # Features for sde\n",
    "        latent_sde = latent_pi\n",
    "        if self.sde_features_extractor is not None:\n",
    "            latent_sde = self.sde_features_extractor(features)\n",
    "        return latent_pi, latent_vf, latent_sde\n",
    "\n",
    "    def _get_action_dist_from_latent(self, latent_pi, latent_sde = None):\n",
    "        \"\"\"\n",
    "        Retrieve action distribution given the latent codes.\n",
    "\n",
    "        :param latent_pi: Latent code for the actor\n",
    "        :param latent_sde: Latent code for the gSDE exploration function\n",
    "        :return: Action distribution\n",
    "        \"\"\"\n",
    "        mean_actions = self.action_net(latent_pi)\n",
    "\n",
    "        if isinstance(self.action_dist, DiagGaussianDistribution):\n",
    "            return self.action_dist.proba_distribution(mean_actions, self.log_std)\n",
    "        elif isinstance(self.action_dist, CategoricalDistribution):\n",
    "            # Here mean_actions are the logits before the softmax\n",
    "            return self.action_dist.proba_distribution(action_logits=mean_actions)\n",
    "        elif isinstance(self.action_dist, MultiCategoricalDistribution):\n",
    "            # Here mean_actions are the flattened logits\n",
    "            return self.action_dist.proba_distribution(action_logits=mean_actions)\n",
    "        elif isinstance(self.action_dist, BernoulliDistribution):\n",
    "            # Here mean_actions are the logits (before rounding to get the binary actions)\n",
    "            return self.action_dist.proba_distribution(action_logits=mean_actions)\n",
    "        elif isinstance(self.action_dist, StateDependentNoiseDistribution):\n",
    "            return self.action_dist.proba_distribution(mean_actions, self.log_std, latent_sde)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action distribution\")\n",
    "\n",
    "\n",
    "    def _predict(self, observation, deterministic = False):\n",
    "        \"\"\"\n",
    "        Get the action according to the policy for a given observation.\n",
    "\n",
    "        :param observation:\n",
    "        :param deterministic: Whether to use stochastic or deterministic actions\n",
    "        :return: Taken action according to the policy\n",
    "        \"\"\"\n",
    "        latent_pi, _, latent_sde = self._get_latent(observation)\n",
    "        distribution = self._get_action_dist_from_latent(latent_pi, latent_sde)\n",
    "        return distribution.get_actions(deterministic=deterministic)\n",
    "\n",
    "    def create_sde_features_extractor(self,\n",
    "            features_dim, sde_net_arch, activation_fn\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create the neural network that will be used to extract features\n",
    "        for the gSDE exploration function.\n",
    "\n",
    "        :param features_dim:\n",
    "        :param sde_net_arch:\n",
    "        :param activation_fn:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Special case: when using states as features (i.e. sde_net_arch is an empty list)\n",
    "        # don't use any activation function\n",
    "        self.sde_activation = activation_fn if len(sde_net_arch) > 0 else None\n",
    "        latent_sde_net = create_mlp(features_dim, -1, sde_net_arch, activation_fn=self.sde_activation, squash_output=False)\n",
    "        latent_sde_dim = sde_net_arch[-1] if len(sde_net_arch) > 0 else features_dim\n",
    "        self.sde_features_extractor = nn.Sequential(*latent_sde_net)\n",
    "        return self.sde_features_extractor, self.latent_sde_dim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "122d6fef-5538-48d5-bffb-e8f92ab55b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    CustomActorCriticPolicy,\n",
    "    env,\n",
    "    verbose=0,\n",
    "    policy_kwargs = {'actions_mask_func': get_actions_mask}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d500b8c8-ffbf-4175-a803-269502c9e044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  1  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testeo de predict\n",
    "model.policy.get_actions_mask(env.reset()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "860228c6-91e8-4a2e-925f-993cc700e972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  1  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  1  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  1  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  1  1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  1  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Playing [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 -1  0  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Encode [[ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  1  1  0  0]\n",
      " [ 0  0  0 -1  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DiagGaussianDistribution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-58fc5de9e29c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/myenv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, mask, deterministic)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecurrent\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \"\"\"\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/myenv/lib/python3.8/site-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, mask, deterministic)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;31m# Convert to numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-c9707c806dc5>\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m    154\u001b[0m         \u001b[0mlatent_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_sde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_action_dist_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_sde\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-c9707c806dc5>\u001b[0m in \u001b[0;36m_get_action_dist_from_latent\u001b[0;34m(self, latent_pi, latent_sde)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mmean_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiagGaussianDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DiagGaussianDistribution' is not defined"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "actions, _ = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf9fbd-5077-4255-8eac-e84462c35378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que las acciones son válidas\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a65995-f994-4f0b-a369-4db7c6981a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testeo de forward\n",
    "model.policy(th.from_numpy(obs).to(model.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b41a057-bfa4-4901-b102-c3d385dedabf",
   "metadata": {},
   "source": [
    "# Corremos PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b2d58-5bd1-4963-8fc0-3a7c65590b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_shape = 8\n",
    "n_envs = 6\n",
    "gamma = 0.99\n",
    "ent_coef = 0.0\n",
    "gae_lambda = 0.95\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565b606-2942-48a4-af53-5c78608e7707",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'Reversi_PPO'\n",
    "suffix = 'masked_actions'\n",
    "model_name = f'{prefix}_{board_shape}by{board_shape}_{gamma}_{gae_lambda}_{ent_coef}_{n_epochs}_{n_envs}_{suffix}'\n",
    "best_model_save_path = f'./models/{model_name}'\n",
    "print(model_name)\n",
    "print(best_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640461a-dd62-4ba1-a8bd-d03509a2789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    CustomActorCriticPolicy,\n",
    "    env,\n",
    "    verbose=0,\n",
    "    tensorboard_log='tensorboard_log',\n",
    "    gamma=gamma,\n",
    "    gae_lambda=gae_lambda,\n",
    "    ent_coef=ent_coef,\n",
    "    n_epochs=n_epochs,\n",
    "    policy_kwargs = {'actions_mask_func': get_actions_mask}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c554a4a-2b95-45cf-a96c-9c836ca45232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147117ff-2ff0-4aa8-a7b6-fb1914d54e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El entorno de evaluación no corre en paralelo por eso uno solo\n",
    "eval_env = make_reversi_vec_env(\n",
    "    SelfPlayEnv, n_envs=1,\n",
    "    env_kwargs={\n",
    "        'board_shape': board_shape,\n",
    "        'LocalPlayer': RandomPlayer\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6e75e-66cd-42d2-a023-ab9f662130b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(\n",
    "    eval_env = eval_env,\n",
    "    eval_freq=1_000,\n",
    "    n_eval_episodes=500,\n",
    "    deterministic=True,\n",
    "    verbose=1,\n",
    "    best_model_save_path=best_model_save_path,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5041b9-700a-473a-9102-6becaad5a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=int(1e10), callback=[eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663594e-87fd-40eb-81a6-529e6504e92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
