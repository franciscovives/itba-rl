{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb5793f-80b2-4c6b-b15b-51abf33c83e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5afaec6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#! pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d1ce19",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#! pip install stable-baselines --upgrade\n",
    "#! pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33af1b03-ba50-43a1-a5e4-7b8f8eddcddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tensorflow\n",
    "#! pip install numpy\n",
    "#! pip install stable-baselines3\n",
    "#! pip install stable-baselines --upgrade\n",
    "#! pip install stable-baselines3[extra]\n",
    "#! pip install beepy\n",
    "#!pip install sklearn\n",
    "#!pip install matplotlib\n",
    "#!pip install pandas\n",
    "#!pip install pandas-summary\n",
    "#!pip install isoweek\n",
    "#!pip install pyarrow\n",
    "#! pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f573cbc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.7.0-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.8/171.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Using cached numpy-1.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Collecting gym==0.21\n",
      "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas\n",
      "  Using cached pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Collecting torch>=1.11\n",
      "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Using cached matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "Collecting importlib-metadata~=4.13\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Collecting cloudpickle\n",
      "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting autorom[accept-rom-license]~=0.4.2\n",
      "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-9.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Collecting ale-py==0.7.4\n",
      "  Downloading ale_py-0.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]) (4.64.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from stable-baselines3[extra]) (5.9.4)\n",
      "Collecting rich\n",
      "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.10.2)\n",
      "Collecting click\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.28.2)\n",
      "Collecting AutoROM.accept-rom-license\n",
      "  Downloading AutoROM.accept-rom-license-0.5.4.tar.gz (12 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata~=4.13->stable-baselines3[extra]) (3.11.0)\n",
      "Collecting protobuf<4,>=3.9.2\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.38.4)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.51.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (66.1.1)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3[extra]) (4.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (23.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines3[extra]) (2022.7.1)\n",
      "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
      "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.14.0 in /opt/conda/lib/python3.10/site-packages (from rich->stable-baselines3[extra]) (2.14.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.2)\n",
      "Collecting libtorrent\n",
      "  Using cached libtorrent-2.0.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.6 MB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
      "Building wheels for collected packages: gym, AutoROM.accept-rom-license\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616794 sha256=7c48f3320cc5c61f734a74c7bbf9424232fc022c07b5fda8214649a97ea695f2\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/b6/16/76/7626b97c5534a18f652c1abadc0e1eae5c01fb3d3322b8ea6f\n",
      "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.5.4-py3-none-any.whl size=448700 sha256=bb80185ca7359f67c85d1e7068987f856129ab3bc8ce97a5cf49808d9c59f3a8\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/2f/6e/2c/9a8b52bb28e5173da5e5e7740d13eee2aa249a2c0e52fe8a65\n",
      "Successfully built gym AutoROM.accept-rom-license\n",
      "\u001b[33mWARNING: Error parsing requirements for attrs: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/attrs-22.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tensorboard-plugin-wit, pyasn1, libtorrent, werkzeug, tensorboard-data-server, rsa, pyparsing, pyasn1-modules, protobuf, pillow, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, mdurl, markdown, kiwisolver, importlib-metadata, grpcio, fonttools, cycler, cloudpickle, click, cachetools, absl-py, requests-oauthlib, pandas, opencv-python, nvidia-cudnn-cu11, markdown-it-py, gym, google-auth, contourpy, AutoROM.accept-rom-license, autorom, ale-py, torch, rich, matplotlib, google-auth-oauthlib, tensorboard, stable-baselines3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.0.0\n",
      "    Uninstalling importlib-metadata-6.0.0:\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\n",
      "Successfully installed AutoROM.accept-rom-license-0.5.4 absl-py-1.4.0 ale-py-0.7.4 autorom-0.4.2 cachetools-5.3.0 click-8.1.3 cloudpickle-2.2.1 contourpy-1.0.7 cycler-0.11.0 fonttools-4.38.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 grpcio-1.51.1 gym-0.21.0 importlib-metadata-4.13.0 kiwisolver-1.4.4 libtorrent-2.0.7 markdown-3.4.1 markdown-it-py-2.1.0 matplotlib-3.6.3 mdurl-0.1.2 numpy-1.24.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 opencv-python-4.7.0.68 pandas-1.5.3 pillow-9.4.0 protobuf-3.20.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 requests-oauthlib-1.3.1 rich-13.3.1 rsa-4.9 stable-baselines3-1.7.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torch-1.13.1 werkzeug-2.2.2\n"
     ]
    }
   ],
   "source": [
    "! pip install stable-baselines3[extra]\n",
    "#! pip install stable-baselines3\n",
    "#! pip install torchdata\n",
    "#! pip install torchtext\n",
    "#! pip install torch-cu100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b78b6e1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#!pip install stable-baselines[mpi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09694e9a-5a9f-44d3-a04a-1dac5fafe9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines==1.0.6\n",
      "  Using cached stable_baselines-1.0.6-py3-none-any.whl (207 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from stable-baselines==1.0.6) (4.64.1)\n",
      "Collecting zmq\n",
      "  Using cached zmq-0.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from stable-baselines==1.0.6) (3.6.3)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from stable-baselines==1.0.6) (2.2.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from stable-baselines==1.0.6) (4.7.0.68)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from stable-baselines==1.0.6) (1.5.3)\n",
      "Collecting pytest\n",
      "  Using cached pytest-7.2.1-py3-none-any.whl (317 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
      "Collecting progressbar2\n",
      "  Using cached progressbar2-4.2.0-py2.py3-none-any.whl (27 kB)\n",
      "Collecting tensorflow>=1.5.0\n",
      "  Using cached tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from stable-baselines==1.0.6) (1.24.1)\n",
      "Requirement already satisfied: gym[atari,classic_control,mujoco,robotics] in /opt/conda/lib/python3.10/site-packages (from stable-baselines==1.0.6) (0.21.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from stable-baselines==1.0.6) (8.1.3)\n",
      "Collecting glob2\n",
      "  Using cached glob2-0.7-py2.py3-none-any.whl\n",
      "Collecting mpi4py\n",
      "  Using cached mpi4py-3.1.4.tar.gz (2.5 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting joblib\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.5.0->stable-baselines==1.0.6) (1.51.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.5.0->stable-baselines==1.0.6) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.5.0->stable-baselines==1.0.6) (66.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.5.0->stable-baselines==1.0.6) (4.4.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.30.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Using cached tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.5.0->stable-baselines==1.0.6) (2.11.2)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.5.0->stable-baselines==1.0.6) (23.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=1.5.0->stable-baselines==1.0.6) (1.4.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: ale-py~=0.7.1 in /opt/conda/lib/python3.10/site-packages (from gym[atari,classic_control,mujoco,robotics]->stable-baselines==1.0.6) (0.7.4)\n",
      "Collecting mujoco-py<2.0,>=1.50\n",
      "  Downloading mujoco-py-1.50.1.68.tar.gz (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyglet>=1.4.0\n",
      "  Downloading pyglet-2.0.3-py3-none-any.whl (968 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m968.6/968.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines==1.0.6) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines==1.0.6) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines==1.0.6) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines==1.0.6) (4.38.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines==1.0.6) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines==1.0.6) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines==1.0.6) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines==1.0.6) (2022.7.1)\n",
      "Collecting python-utils>=3.0.0\n",
      "  Using cached python_utils-3.4.5-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from pytest->stable-baselines==1.0.6) (21.4.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from pytest->stable-baselines==1.0.6) (1.0.0)\n",
      "Collecting iniconfig\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytest->stable-baselines==1.0.6) (2.0.1)\n",
      "Collecting exceptiongroup>=1.0.0rc8\n",
      "  Using cached exceptiongroup-1.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/lib/python3.10/site-packages (from zmq->stable-baselines==1.0.6) (25.0.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.7.1->gym[atari,classic_control,mujoco,robotics]->stable-baselines==1.0.6) (5.10.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=1.5.0->stable-baselines==1.0.6) (0.38.4)\n",
      "Collecting glfw>=1.4.0\n",
      "  Using cached glfw-2.5.5-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n",
      "Collecting Cython>=0.27.2\n",
      "  Downloading Cython-0.29.33-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting imageio>=2.1.2\n",
      "  Using cached imageio-2.25.0-py3-none-any.whl (3.4 MB)\n",
      "Requirement already satisfied: cffi>=1.10 in /opt/conda/lib/python3.10/site-packages (from mujoco-py<2.0,>=1.50->gym[atari,classic_control,mujoco,robotics]->stable-baselines==1.0.6) (1.15.1)\n",
      "Collecting lockfile>=0.12.2\n",
      "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (2.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.10->mujoco-py<2.0,>=1.50->gym[atari,classic_control,mujoco,robotics]->stable-baselines==1.0.6) (2.21)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (1.26.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=1.5.0->stable-baselines==1.0.6) (3.2.2)\n",
      "Building wheels for collected packages: mpi4py, mujoco-py\n",
      "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for mpi4py \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[135 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_src\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/bench.py -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__main__.py -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__init__.py -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/run.py -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/server.py -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__main__.py -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/aplus.py -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__init__.py -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/pool.py -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_base.py -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_lib.py -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_core.py -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/pkl5.py -> build/lib.linux-x86_64-cpython-310/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/__init__.py -> build/lib.linux-x86_64-cpython-310/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/dtlib.py -> build/lib.linux-x86_64-cpython-310/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/py.typed -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/dl.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/bench.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/MPI.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__init__.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/run.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__main__.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/__init__.pxd -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/MPI.pxd -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/libmpi.pxd -> build/lib.linux-x86_64-cpython-310/mpi4py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/mpi4py/include\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.MPI_api.h -> build/lib.linux-x86_64-cpython-310/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.h -> build/lib.linux-x86_64-cpython-310/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.MPI.h -> build/lib.linux-x86_64-cpython-310/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi4py.i -> build/lib.linux-x86_64-cpython-310/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/include/mpi4py/mpi.pxi -> build/lib.linux-x86_64-cpython-310/mpi4py/include/mpi4py\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_core.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/server.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/aplus.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/_lib.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__init__.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/pool.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/futures/__main__.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py/futures\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/pkl5.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/__init__.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m copying src/mpi4py/util/dtlib.pyi -> build/lib.linux-x86_64-cpython-310/mpi4py/util\n",
      "  \u001b[31m   \u001b[0m running build_clib\n",
      "  \u001b[31m   \u001b[0m MPI configuration: [mpi] from 'mpi.cfg'\n",
      "  \u001b[31m   \u001b[0m checking for library 'lmpe' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'mpe' dylib library\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/src\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/src/lib-pmpi\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c src/lib-pmpi/mpe.c -o build/temp.linux-x86_64-cpython-310/src/lib-pmpi/mpe.o\n",
      "  \u001b[31m   \u001b[0m warning: build_clib: command 'gcc' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m warning: build_clib: building optional library \"mpe\" failed\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m checking for library 'vt-mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt.mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'vt' dylib library\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c src/lib-pmpi/vt.c -o build/temp.linux-x86_64-cpython-310/src/lib-pmpi/vt.o\n",
      "  \u001b[31m   \u001b[0m warning: build_clib: command 'gcc' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m warning: build_clib: building optional library \"vt\" failed\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m checking for library 'vt-mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt.mpi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'vt-mpi' dylib library\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c src/lib-pmpi/vt-mpi.c -o build/temp.linux-x86_64-cpython-310/src/lib-pmpi/vt-mpi.o\n",
      "  \u001b[31m   \u001b[0m warning: build_clib: command 'gcc' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m warning: build_clib: building optional library \"vt-mpi\" failed\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m checking for library 'vt-hyb' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m checking for library 'vt.ompi' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'vt-hyb' dylib library\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c src/lib-pmpi/vt-hyb.c -o build/temp.linux-x86_64-cpython-310/src/lib-pmpi/vt-hyb.o\n",
      "  \u001b[31m   \u001b[0m warning: build_clib: command 'gcc' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m warning: build_clib: building optional library \"vt-hyb\" failed\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m MPI configuration: [mpi] from 'mpi.cfg'\n",
      "  \u001b[31m   \u001b[0m checking for dlopen() availability ...\n",
      "  \u001b[31m   \u001b[0m checking for header 'dlfcn.h' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m checking for library 'dl' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m checking for function 'dlopen' ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m building 'mpi4py.dl' extension\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c src/dynload.c -o build/temp.linux-x86_64-cpython-310/src/dynload.o\n",
      "  \u001b[31m   \u001b[0m warning: build_ext: command 'gcc' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m warning: build_ext: building optional extension \"mpi4py.dl\" failed\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m checking for MPI compile and link ...\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/include/python3.10 -c _configtest.c -o _configtest.o\n",
      "  \u001b[31m   \u001b[0m failure.\n",
      "  \u001b[31m   \u001b[0m removing: _configtest.c _configtest.o\n",
      "  \u001b[31m   \u001b[0m error: Cannot compile MPI programs. Check your configuration!!!\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for mpi4py\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Building wheel for mujoco-py (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[34 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-2bxiflpc/mujoco-py_0e3c5c34df3b40c1bdf5b47c54510d17/setup.py\", line 32, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/__init__.py\", line 108, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 1213, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wheel/bdist_wheel.py\", line 325, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 1213, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-2bxiflpc/mujoco-py_0e3c5c34df3b40c1bdf5b47c54510d17/setup.py\", line 28, in run\n",
      "  \u001b[31m   \u001b[0m     import mujoco_py  # noqa: force build\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-2bxiflpc/mujoco-py_0e3c5c34df3b40c1bdf5b47c54510d17/mujoco_py/__init__.py\", line 3, in <module>\n",
      "  \u001b[31m   \u001b[0m     from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-2bxiflpc/mujoco-py_0e3c5c34df3b40c1bdf5b47c54510d17/mujoco_py/builder.py\", line 17, in <module>\n",
      "  \u001b[31m   \u001b[0m     from Cython.Build import cythonize\n",
      "  \u001b[31m   \u001b[0m ModuleNotFoundError: No module named 'Cython'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for mujoco-py\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for mujoco-py\n",
      "Failed to build mpi4py mujoco-py\n",
      "\u001b[31mERROR: Could not build wheels for mpi4py, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install stable-baselines==1.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50a9f67b-265e-401e-85c7-55b3827c9e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boardgame2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmulti_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_reversi_vec_env, SelfPlayEnv\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mth\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomPlayer\n",
      "File \u001b[0;32m~/work/fv/rl_final_project/multi_env.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvec_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DummyVecEnv, VecEnvWrapper\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmonitor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Monitor\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mboardgame2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReversiEnv\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'boardgame2'"
     ]
    }
   ],
   "source": [
    "from multi_env import make_reversi_vec_env, SelfPlayEnv\n",
    "import torch as th\n",
    "from players import RandomPlayer\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1e9b5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#from stable_baselines3.common.torch_layers import CombinedExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33344faf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07411d1-263f-445f-9dc8-92ef55cd4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_shape = 8\n",
    "n_envs = 10\n",
    "env = make_reversi_vec_env(\n",
    "    SelfPlayEnv, n_envs=n_envs,\n",
    "    env_kwargs={\n",
    "        'board_shape': board_shape,\n",
    "        'LocalPlayer': RandomPlayer\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f7b6a-ab0b-495f-9b9b-03220308f75b",
   "metadata": {},
   "source": [
    "# Modificación de librería para que haga argmax solo sobre las válidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65966e76-d302-40f5-be6a-1b00565194cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    ActorCriticPolicy,\n",
    "    env,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac109405-906a-4c2e-92bd-0ab6d8146190",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_reset = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8434cd9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.predict(env_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8ae4f-2113-4031-8b6a-3b8210285937",
   "metadata": {},
   "source": [
    "# Custom ActorCriticPolicy \n",
    "\n",
    "https://github.com/DLR-RM/stable-baselines3/blob/master/stable_baselines3/common/policies.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4552377-3076-44dd-a6d4-d504b5915e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boardgame2 import ReversiEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9569a-4fed-4508-8cbd-73b7aac5058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_not_vect = ReversiEnv(board_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b019a5d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "state = env_reset[0][0]\n",
    "player = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192644c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "env_reset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58553f62-ab53-41b9-9815-df9706caffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_not_vect.get_valid((env_reset[0][0], player))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87a3684",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "env_not_vect.get_valid((env_reset[2][0], player))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898c124-9b43-4088-a366-03adc8b31ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions_mask(state):\n",
    "    player = 1\n",
    "    valid_actions = env_not_vect.get_valid((state, player))\n",
    "    return valid_actions.reshape(-1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92fe71-689f-4a7f-8f0b-4ee7453a4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_actions_mask(env.reset()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d094ad",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#from policies_custom import ActorCriticCnnPolicy as ActorCriticCnnPolicy_Custom\n",
    "#from stable_baselines3.common.policies import *\n",
    "from policies import ActorCriticPolicy as ActorCriticPolicy_Policies\n",
    "from policies_url_org import ActorCriticPolicy as ActorCriticPolicy_PCustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55d689",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class CustomActorCriticPolicy(ActorCriticPolicy_Policies):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args, # Todos los argumentos posicionales de ActorCriticPolicy\n",
    "        actions_mask_func=None, # El nuevo argumento\n",
    "        **kwargs # Todos los argumentos opcionales de ActorCriticPolicy\n",
    "    ):\n",
    "        super(CustomActorCriticPolicy, self).__init__(\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        if actions_mask_func:\n",
    "            self.get_actions_mask = actions_mask_func\n",
    "\n",
    "\n",
    "    def sample_masked_actions(self, obs, distribution, deterministic=False, return_distribution=False):\n",
    "        def get_mask(obs):\n",
    "            masks = np.zeros((len(obs), obs.shape[-1] * obs.shape[-2]))\n",
    "            for i, board in enumerate(obs):\n",
    "                board = board[0].cpu().numpy()\n",
    "                masks[i] = 1 - self.get_actions_mask(board)\n",
    "            return th.from_numpy(masks).to(self.device)\n",
    "        masks = get_mask(obs)\n",
    "        masks[masks == 1] = -np.inf\n",
    "        masked_logits = distribution.logits + masks\n",
    "        if return_distribution:\n",
    "            return th.distributions.Categorical(logits=masked_logits)\n",
    "        if deterministic:\n",
    "            return th.argmax(masked_logits, axis=1)\n",
    "        return th.distributions.Categorical(logits=masked_logits).sample()\n",
    "\n",
    "\n",
    "\n",
    "    def sample_masked_actions2(self, obs, distribution, deterministic=False, return_distribution=False):\n",
    "        # Dada las obs y distribuciones luego de evaluar la red neuronal, samplear solo las acciones válidas\n",
    "        # Las obs se usan para que con self.get_actions_mask se obtengan las acciones válidas\n",
    "        # las distribuciones son el resultado de evaluar la red neuronal y van a dar acciones no validas\n",
    "        # Generar una nueva distribución (del lado de los logits preferentemente) donde las acciones no válidas\n",
    "        # tengan probabildad nula de ser muestreadas\n",
    "        # Luego se modifican abajo los métodos\n",
    "        # _predict, forward y evaluate_actions\n",
    "        # Si tiene el flag de return_distribution en true devuelve la distribución nueva\n",
    "        # Caso contrario devuelve las acciones\n",
    "        # Para tener en cuenta, obs tiene dimensión [batch_size, channels, H, W]\n",
    "        # Recomendamos poner un print(obs.shape)\n",
    "        # y correr:\n",
    "        # obs = env.reset()\n",
    "        # actions, _ = model.predict(obs)\n",
    "        # Para sacarse las dudas\n",
    "\n",
    "        masked_logits = np.asarray([])\n",
    "        for i, obs in enumerate(obs):\n",
    "            board = obs[0]\n",
    "            acc = self.get_actions_mask(board).astype(np.float32)\n",
    "            masked_logits = np.append(masked_logits, th.from_numpy(acc))\n",
    "        masked_logits = th.from_numpy(masked_logits)\n",
    "\n",
    "        if distribution:\n",
    "            return th.distributions.Categorical(logits=masked_logits)\n",
    "        if deterministic:\n",
    "            return th.argmax(masked_logits, axis=1)\n",
    "        return th.distributions.Categorical(logits=masked_logits).sample()\n",
    "    \n",
    "    def _predict2(self, observation, deterministic=False):\n",
    "        \"\"\"\n",
    "        Get the action according to the policy for a given observation.\n",
    "        :param observation:\n",
    "        :param deterministic: Whether to use stochastic or deterministic actions\n",
    "        :return: Taken action according to the policy\n",
    "        \"\"\"\n",
    "        latent_pi, _, latent_sde = self._get_latent(observation)\n",
    "        distribution = self._get_action_dist_from_latent(latent_pi, latent_sde)\n",
    "        \n",
    "        if self.get_actions_mask:\n",
    "            actions = self.sample_masked_actions(observation, distribution.distribution, deterministic=deterministic)\n",
    "        else:\n",
    "            actions = distribution.get_actions(deterministic=deterministic)\n",
    "        \n",
    "        return actions\n",
    "    \n",
    "    def forward2(self, obs, deterministic = False):\n",
    "        \"\"\"\n",
    "        Forward pass in all the networks (actor and critic)\n",
    "        :param obs: Observation\n",
    "        :param deterministic: Whether to sample or use deterministic actions\n",
    "        :return: action, value and log probability of the action\n",
    "        \"\"\"\n",
    "        latent_pi, latent_vf, latent_sde = self._get_latent(obs)\n",
    "        # Evaluate the values for the given observations\n",
    "        values = self.value_net(latent_vf)\n",
    "        distribution = self._get_action_dist_from_latent(latent_pi, latent_sde=latent_sde)\n",
    "        \n",
    "        \n",
    "        if self.get_actions_mask:\n",
    "            actions = self.sample_masked_actions(obs, distribution.distribution, deterministic=deterministic)\n",
    "        else:\n",
    "            actions = distribution.get_actions(deterministic=deterministic)\n",
    "\n",
    "        log_prob = distribution.log_prob(actions)\n",
    "        return actions, values, log_prob\n",
    "    \n",
    "    def evaluate_actions2(self, obs, actions):\n",
    "        \"\"\"\n",
    "        Evaluate actions according to the current policy,\n",
    "        given the observations.\n",
    "        :param obs:\n",
    "        :param actions:\n",
    "        :return: estimated value, log likelihood of taking those actions\n",
    "            and entropy of the action distribution.\n",
    "        \"\"\"\n",
    "        latent_pi, latent_vf, latent_sde = self._get_latent(obs)\n",
    "        distribution = self._get_action_dist_from_latent(latent_pi, latent_sde)\n",
    "        distrib = self.sample_masked_actions(obs, distribution.distribution, return_distribution=True)\n",
    "\n",
    "        log_prob = distrib.log_prob(actions)\n",
    "        values = self.value_net(latent_vf)\n",
    "        return values, log_prob, distrib.entropy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d6fef-5538-48d5-bffb-e8f92ab55b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = {'actions_mask_func': get_actions_mask, 'net_arch': dict()}\n",
    "#policy_kwargs = {'actions_mask_func': get_actions_mask}\n",
    "model = PPO(\n",
    "    CustomActorCriticPolicy,\n",
    "    env,\n",
    "    verbose=1,\n",
    "    policy_kwargs = policy_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500b8c8-ffbf-4175-a803-269502c9e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testeo de predict\n",
    "model.policy.get_actions_mask(env.reset()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860228c6-91e8-4a2e-925f-993cc700e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "actions, _ = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bf9fbd-5077-4255-8eac-e84462c35378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que las acciones son válidas\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee3497",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#np.arange(6).dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a65995-f994-4f0b-a369-4db7c6981a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testeo de forward\n",
    "#model.policy(th.from_numpy(obs).to(model.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b41a057-bfa4-4901-b102-c3d385dedabf",
   "metadata": {},
   "source": [
    "# Corremos PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b2d58-5bd1-4963-8fc0-3a7c65590b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_shape = 8\n",
    "n_envs = 6\n",
    "gamma = 0.99\n",
    "ent_coef = 0.0\n",
    "gae_lambda = 0.95\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565b606-2942-48a4-af53-5c78608e7707",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'Reversi_PPO'\n",
    "suffix = 'masked_actions'\n",
    "model_name = f'{prefix}_{board_shape}by{board_shape}_{gamma}_{gae_lambda}_{ent_coef}_{n_epochs}_{n_envs}_{suffix}'\n",
    "best_model_save_path = f'./models/{model_name}'\n",
    "print(model_name)\n",
    "print(best_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640461a-dd62-4ba1-a8bd-d03509a2789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    CustomActorCriticPolicy,\n",
    "    env,\n",
    "    verbose=0,\n",
    "    tensorboard_log='tensorboard_log',\n",
    "    gamma=gamma,\n",
    "    gae_lambda=gae_lambda,\n",
    "    ent_coef=ent_coef,\n",
    "    n_epochs=n_epochs,\n",
    "    policy_kwargs = policy_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c554a4a-2b95-45cf-a96c-9c836ca45232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147117ff-2ff0-4aa8-a7b6-fb1914d54e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El entorno de evaluación no corre en paralelo por eso uno solo\n",
    "eval_env = make_reversi_vec_env(\n",
    "    SelfPlayEnv, n_envs=1,\n",
    "    env_kwargs={\n",
    "        'board_shape': board_shape,\n",
    "        'LocalPlayer': RandomPlayer\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6e75e-66cd-42d2-a023-ab9f662130b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(\n",
    "    eval_env = eval_env,\n",
    "    eval_freq=1_000,\n",
    "    n_eval_episodes=500,\n",
    "    deterministic=True,\n",
    "    verbose=1,\n",
    "    best_model_save_path=best_model_save_path,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5041b9-700a-473a-9102-6becaad5a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.learn(total_timesteps=int(1e10), callback=[eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b63f2ca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#model.save(\"monitor/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35338df6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#! pip install beepy\n",
    "import beepy\n",
    "beepy.beep(sound=1)\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663594e-87fd-40eb-81a6-529e6504e92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
